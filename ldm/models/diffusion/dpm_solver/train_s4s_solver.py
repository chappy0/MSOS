# S4S_training.py



import torch
import torch.nn as nn
import numpy as np
import os
import logging
from tqdm import tqdm
import random
import lpips # å¯¼å…¥LPIPSåº“

# å¯¼å…¥æ‚¨ç°æœ‰çš„æ¨¡å—
from ldm.util import instantiate_from_config
from omegaconf import OmegaConf
from pytorch_lightning import seed_everything
# æˆ‘ä»¬éœ€è¦ä¸€ä¸ªé«˜è´¨é‡çš„æ•™å¸ˆæ±‚è§£å™¨ï¼Œä¾‹å¦‚DPM-Solver++
# from ldm.models.diffusion.dpm_solver import DPMSolverSampler
from ldm.models.diffusion.dpm_solver.sampler import DPMSolverSampler
from ldm.util import instantiate_from_config


# S4S_training.py

# ===================================================================
# # --- ç»ˆæè¯Šæ–­ä¸ä¿®å¤æ–¹æ¡ˆ ---
# import logging
# import sys
# import os

# # --- è¯Šæ–­éƒ¨åˆ† ---
# # æ‰“å°å‡ºPythonè§£é‡Šå™¨è®¤ä¸ºçš„â€œå½“å‰å·¥ä½œç›®å½•â€
# # è¿™èƒ½å‘Šè¯‰æˆ‘ä»¬è„šæœ¬æ˜¯ä»å“ªä¸ªæ–‡ä»¶å¤¹å¯åŠ¨çš„
# print("="*50)
# print(f"ğŸ [DIAGNOSTIC] Current Working Directory: {os.getcwd()}")

# # æ‰“å°å‡ºPythonè§£é‡Šå™¨å½“å‰çš„å®Œæ•´æ¨¡å—æœç´¢è·¯å¾„
# print("ğŸ [DIAGNOSTIC] Current sys.path:")
# for i, path in enumerate(sys.path):
#     print(f"   {i}: {path}")
# print("="*50)

# # --- ç¡¬ç¼–ç ä¿®å¤éƒ¨åˆ† ---
# # è¯·å°†ä¸‹é¢çš„è·¯å¾„æ›¿æ¢ä¸ºæ‚¨é¡¹ç›®çš„ç»å¯¹æ ¹ç›®å½•è·¯å¾„
# # åœ¨Windowsä¸Šï¼Œè¯·ä½¿ç”¨åŒåæ–œæ '\\'æˆ–æ­£æ–œæ '/'
# # ä¾‹å¦‚: "d:/paper/stablediffusion-main" æˆ– "d:\\paper\\stablediffusion-main"
# PROJECT_ROOT_PATH = r"d:\paper\stablediffusion-main" # <--- !!! è¯·ç¡®ä¿è¿™ä¸ªè·¯å¾„æ˜¯æ­£ç¡®çš„ !!!

# # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æŠ¥é”™
# if not os.path.isdir(PROJECT_ROOT_PATH):
#     raise FileNotFoundError(f"Error: The hardcoded project root path does not exist: {PROJECT_ROOT_PATH}")
# if not os.path.isdir(os.path.join(PROJECT_ROOT_PATH, 'ldm')):
#      raise FileNotFoundError(f"Error: The 'ldm' folder was not found inside the project root: {os.path.join(PROJECT_ROOT_PATH, 'ldm')}")

# # å°†è¿™ä¸ªç¡¬ç¼–ç çš„è·¯å¾„å¼ºåˆ¶æ’å…¥åˆ°æœç´¢åˆ—è¡¨çš„æœ€å‰é¢
# if PROJECT_ROOT_PATH not in sys.path:
#     sys.path.insert(0, PROJECT_ROOT_PATH)
#     print(f"âœ… [FIX] Hardcoded project root to Python path: {PROJECT_ROOT_PATH}")

# # ===================================================================

# # ç°åœ¨å¯ä»¥å®‰å…¨åœ°ä»ldmå¯¼å…¥äº†
# try:
#     from ldm.models.diffusion.dpm_solver.sampler import DPMSolverSampler
#     from ldm.util import instantiate_from_config
#     print("âœ… [SUCCESS] Successfully imported 'ldm' module.")
# except ModuleNotFoundError as e:
#     print(f"âŒ [FAILURE] Still failed to import 'ldm' module after hardcoding path.")
#     print("   Please double-check that the PROJECT_ROOT_PATH is set correctly and that the 'ldm' folder exists directly inside it.")
#     raise e

# ... æ‚¨è„šæœ¬ä¸­å…¶ä½™æ‰€æœ‰çš„importå’Œä»£ç  ...
# import torch
# import torch.nn as nn
# ...
# --- æ—¥å¿—è®°å½•è®¾ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

# --- é…ç½®åŒº ---
# æ¨¡å‹å’Œè°ƒåº¦è·¯å¾„ (è¯·æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹)
CONFIG_PATH = r"D:\paper\stablediffusion-main\configs\stable-diffusion\v2-inference.yaml"
CKPT_PATH = r"D:\paper\FCDiffusion_code-main\models\v2-1_512-ema-pruned.ckpt"
SCHEDULE_PATH = r"D:\paper\stablediffusion-main\pre_compute\schedule.txt" # å‡è®¾è¿™æ˜¯æˆ‘ä»¬ä¸º10æ­¥ä¼˜åŒ–çš„è°ƒåº¦æ–‡ä»¶

# è®­ç»ƒè¶…å‚æ•°
N_TEACHER_STEPS = 100        # æ•™å¸ˆæ±‚è§£å™¨çš„æ­¥æ•°
STUDENT_ORDER = 3            # å­¦ç”Ÿæ±‚è§£å™¨çš„é˜¶æ•° (ä½¿ç”¨å†å²æ­¥æ•°)
TRAINING_STEPS = 300         # è®­ç»ƒå­¦ç”Ÿæ±‚è§£å™¨çš„æ€»è¿­ä»£æ¬¡æ•°
LEARNING_RATE = 1e-3         # å­¦ä¹ ç‡
BATCH_SIZE = 1               # æ¯æ¬¡åªç”¨ä¸€å¼ å›¾çš„è½¨è¿¹è¿›è¡Œè®­ç»ƒ
GUIDANCE_SCALE = 7.5         # ç”Ÿæˆæ•™å¸ˆè½¨è¿¹æ—¶ä½¿ç”¨çš„CFG
LPIPS_WEIGHT = 1.0           # æ„ŸçŸ¥æŸå¤±çš„æƒé‡
L2_WEIGHT = 0.1              # L2æŸå¤±çš„æƒé‡ (å¯é€‰ï¼Œç”¨äºç¨³å®šè®­ç»ƒ)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


@torch.no_grad()
def generate_teacher_trajectory(model, sampler, n_teacher_steps, student_schedule_t, prompt, guidance_scale):
    """
    ä½¿ç”¨é«˜NFEçš„æ•™å¸ˆæ±‚è§£å™¨ï¼Œç”Ÿæˆåœ¨å­¦ç”Ÿè°ƒåº¦æ—¶é—´ç‚¹ä¸Šçš„â€œæ­£ç¡®â€latentçŠ¶æ€ã€‚
    """
    logging.info(f"Generating teacher trajectory with {n_teacher_steps} steps...")
    
    # æ•™å¸ˆæ±‚è§£å™¨ä½¿ç”¨è‡ªå·±çš„é«˜å¯†åº¦è°ƒåº¦ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„å®Œæ•´è½¨è¿¹
    teacher_samples, teacher_intermediates = sampler.sample(
        S=n_teacher_steps,
        conditioning=model.get_learned_conditioning(BATCH_SIZE * [prompt]).to(DEVICE),
        batch_size=BATCH_SIZE,
        shape=[4, 64, 64], # For 512x512 image
        verbose=False,
        unconditional_guidance_scale=guidance_scale,
        unconditional_conditioning=model.get_learned_conditioning(BATCH_SIZE * [""]).to(DEVICE),
        return_intermediates=True,
    )
    
    # teacher_intermediates['x_inter'] åŒ…å«äº† n_teacher_steps + 1 ä¸ªç‚¹çš„è½¨è¿¹
    teacher_full_trajectory = teacher_intermediates['x_inter'].squeeze(1) # ç§»é™¤å¤šä½™çš„batchç»´åº¦
    teacher_full_timesteps = sampler.get_timesteps(n_teacher_steps)

    # ä¸ºäº†ä»æ•™å¸ˆè½¨è¿¹ä¸­ç²¾ç¡®é‡‡æ ·ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œæ’å€¼
    from scipy.interpolate import interp1d
    
    student_t_cpu = student_schedule_t.cpu().numpy()
    teacher_t_cpu = teacher_full_timesteps.cpu().numpy()
    
    # å°†è½¨è¿¹å˜å½¢ä»¥è¿›è¡Œæ’å€¼
    C, H, W = teacher_full_trajectory.shape[1:]
    teacher_flat = teacher_full_trajectory.view(-1, C * H * W).cpu().numpy()

    # åˆ›å»ºæ’å€¼å‡½æ•° (ç¡®ä¿tæ˜¯é€’å‡çš„ï¼Œscipyè¦æ±‚xé€’å¢)
    sort_idx = np.argsort(teacher_t_cpu)[::-1]
    interpolator = interp1d(teacher_t_cpu[sort_idx], teacher_flat[sort_idx], axis=0, kind='linear', fill_value="extrapolate")
    
    # åœ¨å­¦ç”Ÿçš„æ—¶é—´ç‚¹ä¸Šè¿›è¡Œæ’å€¼
    student_true_latents_flat = interpolator(student_t_cpu)
    
    student_true_latents = torch.from_numpy(student_true_latents_flat).view(-1, C, H, W).to(DEVICE)
    logging.info("Teacher trajectory generated and interpolated successfully.")
    return student_true_latents

class LearnableSolver(nn.Module):
    """
    ä¸€ä¸ªå¯å­¦ä¹ çš„çº¿æ€§å¤šæ­¥æ±‚è§£å™¨ã€‚
    å®ƒçš„å‚æ•°æ˜¯å†å²ä¿¡æ¯çš„ç»„åˆæƒé‡ã€‚
    """
    def __init__(self, order=3, nfe=10):
        super().__init__()
        self.order = order
        # ä¸ºæ¯ä¸ªé‡‡æ ·æ­¥éª¤å­¦ä¹ ä¸€ç»„ç‹¬ç«‹çš„ç³»æ•°ï¼Œèƒ½è¾¾åˆ°æ›´å¥½çš„æ•ˆæœ
        # æ€»å…±æœ‰ nfe ä¸ªæ›´æ–°æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éœ€è¦ order-1 ä¸ªç³»æ•°
        self.coeffs = nn.Parameter(torch.zeros(nfe, self.order - 1))

    def get_d_i(self, eps_curr, history_eps, step_index):
        """
        æ ¹æ®å½“å‰å’Œå†å²çš„å™ªå£°é¢„æµ‹ï¼Œè®¡ç®—ä¿®æ­£åçš„å™ªå£°æ–¹å‘ d_iã€‚
        """
        if not history_eps: # ç¬¬ä¸€æ­¥ï¼Œæ²¡æœ‰å†å²ä¿¡æ¯
            return eps_curr

        # æå–å½“å‰æ­¥éª¤å¯¹åº”çš„ç³»æ•°
        step_coeffs = self.coeffs[step_index]

        correction = torch.zeros_like(eps_curr)
        num_history_to_use = min(len(history_eps), len(step_coeffs))
        for i in range(num_history_to_use):
            correction += step_coeffs[i] * (eps_curr - history_eps[i])
            
        d_i = eps_curr + correction
        return d_i
    
def main():
    # --- 1. ç¯å¢ƒå’Œæ¨¡å‹è®¾ç½® ---
    seed_everything(42)
    
    # åŠ è½½é¢„è®­ç»ƒçš„Stable Diffusionæ¨¡å‹
    config = OmegaConf.load(CONFIG_PATH)
    model = instantiate_from_config(config.model)
    ckpt = torch.load(CKPT_PATH, map_location="cpu")
    model.load_state_dict(ckpt["state_dict"], strict=False)
    model.to(torch.float32) # ç¡®ä¿æ¨¡å‹æ˜¯float32
    model = model.to(DEVICE).eval()

    # --- 2. å‡†å¤‡è°ƒåº¦å’Œæ±‚è§£å™¨ ---
    # åŠ è½½æˆ‘ä»¬é€šè¿‡MuSOSæ‰¾åˆ°çš„æœ€ä¼˜è°ƒåº¦ T*
    student_schedule_t = torch.from_numpy(np.loadtxt(SCHEDULE_PATH, dtype=np.float32)).to(DEVICE)
    NFE = len(student_schedule_t) - 1
    logging.info(f"Loaded student schedule with {NFE} steps from {SCHEDULE_PATH}")

    # å®ä¾‹åŒ–æ•™å¸ˆæ±‚è§£å™¨
    teacher_sampler = DPMSolverSampler(model)

    # å®ä¾‹åŒ–å­¦ç”Ÿæ±‚è§£å™¨
    student_solver = LearnableSolver(order=STUDENT_ORDER, nfe=NFE).to(DEVICE)

    # è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(student_solver.parameters(), lr=LEARNING_RATE)
    loss_fn_lpips = lpips.LPIPS(net='alex').to(DEVICE)
    loss_fn_l2 = nn.MSELoss()

    # --- 3. å¼€å§‹è®­ç»ƒå¾ªç¯ ---
    logging.info("Starting S4S Solver Training...")
    pbar = tqdm(range(TRAINING_STEPS))
    for step in pbar:
        optimizer.zero_grad()
        
        # ä¸ºäº†è®­ç»ƒç¨³å®šï¼Œæ¯æ¬¡è¿­ä»£ä½¿ç”¨å›ºå®šçš„promptå’Œseed
        prompt = "a photograph of an astronaut riding a horse"
        seed_everything(42 + step) # ä¹Ÿå¯ä»¥ç”¨ä¸åŒpromptå’Œseedå¢åŠ æ³›åŒ–æ€§

        # --- A. ç”Ÿæˆæ•™å¸ˆæ•°æ® ---
        teacher_latents = generate_teacher_trajectory(model, teacher_sampler, N_TEACHER_STEPS, student_schedule_t, prompt, GUIDANCE_SCALE)
        
        # --- B. è¿è¡Œå­¦ç”Ÿæ±‚è§£å™¨ ---
        # ä½¿ç”¨ä¸æ•™å¸ˆç›¸åŒçš„åˆå§‹å™ªå£°
        student_x_curr = teacher_latents[0:1].clone() 
        eps_history = []
        
        # æ¨¡æ‹ŸNFEæ­¥é‡‡æ ·
        for i in range(NFE):
            t_curr, t_next = student_schedule_t[i], student_schedule_t[i+1]
            
            with torch.no_grad():
                uncond_eps = model.model.diffusion_model(student_x_curr, t_curr, context=model.get_learned_conditioning([""]).to(DEVICE))
                cond_eps = model.model.diffusion_model(student_x_curr, t_curr, context=model.get_learned_conditioning([prompt]).to(DEVICE))
                eps_curr = uncond_eps + GUIDANCE_SCALE * (cond_eps - uncond_eps)

            # è·å–å­¦ç”Ÿæ±‚è§£å™¨é¢„æµ‹çš„å™ªå£°æ–¹å‘
            d_i = student_solver.get_d_i(eps_curr, eps_history, step_index=i)
            
            # ä½¿ç”¨æ ‡å‡†çš„DDIMæ›´æ–°æ–¹ç¨‹æ¥æ‰§è¡Œä¸€æ­¥ï¼ˆè¿™æ˜¯S4Sè®ºæ–‡ä¸­çš„åšæ³•ï¼‰
            # alpha_t, alpha_t_prev = model.alphas_cumprod[t_curr], model.alphas_cumprod[t_next] # è¿™éœ€è¦ä»tå€¼æ˜ å°„åˆ°ç¦»æ•£ç´¢å¼•
            # pred_x0 = (student_x_curr - torch.sqrt(1 - alpha_t) * d_i) / torch.sqrt(alpha_t)
            # dir_xt = torch.sqrt(1 - alpha_t_prev) * d_i
            # student_x_next = torch.sqrt(alpha_t_prev) * pred_x0 + dir_xt
            
            # ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨samplerçš„å•æ­¥å‡½æ•°ï¼Œä½†ä¼ å…¥æˆ‘ä»¬è‡ªå·±è®¡ç®—çš„d_i
            # æ³¨æ„ï¼šè¿™éœ€è¦ä¿®æ”¹samplerä»¥æ¥å—ä¸€ä¸ªå¤–éƒ¨çš„d_iï¼Œæˆ–è€…åœ¨è¿™é‡Œå¤ç°æ›´æ–°é€»è¾‘
            # ä¸‹é¢æ˜¯ä¸€ä¸ªç®€åŒ–çš„ã€ç±»ä¼¼DDIMçš„æ›´æ–°é€»è¾‘ç¤ºä¾‹ï¼Œæ‚¨éœ€è¦æ ¹æ®æ‚¨çš„UniPC/DPMå…¬å¼é€‚é…
            alpha_t, sigma_t = model.ns.marginal_alpha(t_curr), model.ns.marginal_std(t_curr)
            alpha_next, sigma_next = model.ns.marginal_alpha(t_next), model.ns.marginal_std(t_next)
            
            pred_x0 = (student_x_curr - sigma_t * d_i) / alpha_t
            student_x_curr = alpha_next * pred_x0 + sigma_next * d_i


            # æ›´æ–°å†å²
            eps_history.insert(0, eps_curr.detach())
            if len(eps_history) >= student_solver.order - 1:
                eps_history.pop()

        # å­¦ç”Ÿæœ€ç»ˆå¾—åˆ°çš„latent
        student_final_latent = student_x_curr

        # --- C. è®¡ç®—æŸå¤± ---
        # æ¯”è¾ƒå­¦ç”Ÿå’Œæ•™å¸ˆåœ¨æœ€åä¸€æ­¥çš„latentçš„L2è·ç¦»
        l2_loss = loss_fn_l2(student_final_latent, teacher_latents[-1:])
        
        # æ¯”è¾ƒæœ€ç»ˆç”Ÿæˆå›¾åƒçš„LPIPSè·ç¦»
        with torch.no_grad():
             teacher_final_image = model.decode_first_stage(teacher_latents[-1:])
        student_final_image = model.decode_first_stage(student_final_latent)
        lpips_loss = loss_fn_lpips(student_final_image, teacher_final_image).mean()
        
        # æ€»æŸå¤±
        total_loss = LPIPS_WEIGHT * lpips_loss + L2_WEIGHT * l2_loss
        
        # --- D. æ›´æ–° ---
        total_loss.backward()
        optimizer.step()
        
        pbar.set_description(f"Epoch {step}, Total Loss: {total_loss.item():.4f}, LPIPS: {lpips_loss.item():.4f}, L2: {l2_loss.item():.4f}")

    # --- 4. è®­ç»ƒå®Œæˆï¼Œä¿å­˜å¹¶æ‰“å°å­¦åˆ°çš„ç³»æ•° ---
    logging.info("S4S Solver training complete.")
    best_coeffs = student_solver.coeffs.detach().cpu().numpy()
    logging.info(f"Learned Coefficients:\n{best_coeffs}")
    
    # ä¿å­˜ç³»æ•°ï¼Œä»¥ä¾¿åœ¨é‡‡æ ·æ—¶ä½¿ç”¨
    np.save(f"s4s_coeffs_nfe{NFE}.npy", best_coeffs)
    logging.info(f"Coefficients saved to s4s_coeffs_nfe{NFE}.npy")


if __name__ == '__main__':
    # ç¡®ä¿æ‚¨çš„æ¨¡å‹ã€é‡‡æ ·å™¨å’Œè·¯å¾„éƒ½å·²æ­£ç¡®è®¾ç½®
    main()
